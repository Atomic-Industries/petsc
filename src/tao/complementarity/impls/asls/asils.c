#include <../src/tao/complementarity/impls/ssls/ssls.h>
/*
   Context for ASXLS
     -- active-set      - reduced matrices formed
                          - inherit properties of original system
     -- semismooth (S)  - function not differentiable
                        - merit function continuously differentiable
                        - Fischer-Burmeister reformulation of complementarity
                          - Billups composition for two finite bounds
     -- infeasible (I)  - iterates not guaranteed to remain within bounds
     -- feasible (F)    - iterates guaranteed to remain within bounds
     -- linesearch (LS) - Armijo rule on direction

   Many other reformulations are possible and combinations of
   feasible/infeasible and linesearch/trust region are possible.

   Basic theory
     Fischer-Burmeister reformulation is semismooth with a continuously
     differentiable merit function and strongly semismooth if the F has
     lipschitz continuous derivatives.

     Every accumulation point generated by the algorithm is a stationary
     point for the merit function.  Stationary points of the merit function
     are solutions of the complementarity problem if
       a.  the stationary point has a BD-regular subdifferential, or
       b.  the Schur complement F'/F'_ff is a P_0-matrix where ff is the
           index set corresponding to the free variables.

     If one of the accumulation points has a BD-regular subdifferential then
       a.  the entire sequence converges to this accumulation point at
           a local q-superlinear rate
       b.  if in addition the reformulation is strongly semismooth near
           this accumulation point, then the algorithm converges at a
           local q-quadratic rate.

   The theory for the feasible version follows from the feasible descent
   algorithm framework.

   References:
+  * - Billups, "Algorithms for Complementarity Problems and Generalized
       Equations," Ph.D thesis, University of Wisconsin  Madison, 1995.
.  * - De Luca, Facchinei, Kanzow, "A Semismooth Equation Approach to the
       Solution of Nonlinear Complementarity Problems," Mathematical
       Programming, 75, 1996.
.  * - Ferris, Kanzow, Munson, "Feasible Descent Algorithms for Mixed
       Complementarity Problems," Mathematical Programming, 86,
       1999.
.  * - Fischer, "A Special Newton type Optimization Method," Optimization,
       24, 1992
-  * - Munson, Facchinei, Ferris, Fischer, Kanzow, "The Semismooth Algorithm
       for Large Scale Complementarity Problems," Technical Report,
       University of Wisconsin  Madison, 1999.
*/

static PetscErrorCode TaoSetUp_ASILS(Tao tao)
{
  TAO_SSLS       *asls = (TAO_SSLS *)tao->data;

  PetscFunctionBegin;
  CHKERRQ(VecDuplicate(tao->solution,&tao->gradient));
  CHKERRQ(VecDuplicate(tao->solution,&tao->stepdirection));
  CHKERRQ(VecDuplicate(tao->solution,&asls->ff));
  CHKERRQ(VecDuplicate(tao->solution,&asls->dpsi));
  CHKERRQ(VecDuplicate(tao->solution,&asls->da));
  CHKERRQ(VecDuplicate(tao->solution,&asls->db));
  CHKERRQ(VecDuplicate(tao->solution,&asls->t1));
  CHKERRQ(VecDuplicate(tao->solution,&asls->t2));
  asls->fixed = NULL;
  asls->free = NULL;
  asls->J_sub = NULL;
  asls->Jpre_sub = NULL;
  asls->w = NULL;
  asls->r1 = NULL;
  asls->r2 = NULL;
  asls->r3 = NULL;
  asls->dxfree = NULL;
  PetscFunctionReturn(0);
}

static PetscErrorCode Tao_ASLS_FunctionGradient(TaoLineSearch ls, Vec X, PetscReal *fcn,  Vec G, void *ptr)
{
  Tao            tao = (Tao)ptr;
  TAO_SSLS       *asls = (TAO_SSLS *)tao->data;

  PetscFunctionBegin;
  CHKERRQ(TaoComputeConstraints(tao, X, tao->constraints));
  CHKERRQ(VecFischer(X,tao->constraints,tao->XL,tao->XU,asls->ff));
  CHKERRQ(VecNorm(asls->ff,NORM_2,&asls->merit));
  *fcn = 0.5*asls->merit*asls->merit;

  CHKERRQ(TaoComputeJacobian(tao,tao->solution,tao->jacobian,tao->jacobian_pre));
  CHKERRQ(MatDFischer(tao->jacobian, tao->solution, tao->constraints,tao->XL, tao->XU, asls->t1, asls->t2,asls->da, asls->db));
  CHKERRQ(VecPointwiseMult(asls->t1, asls->ff, asls->db));
  CHKERRQ(MatMultTranspose(tao->jacobian,asls->t1,G));
  CHKERRQ(VecPointwiseMult(asls->t1, asls->ff, asls->da));
  CHKERRQ(VecAXPY(G,1.0,asls->t1));
  PetscFunctionReturn(0);
}

static PetscErrorCode TaoDestroy_ASILS(Tao tao)
{
  TAO_SSLS       *ssls = (TAO_SSLS *)tao->data;

  PetscFunctionBegin;
  CHKERRQ(VecDestroy(&ssls->ff));
  CHKERRQ(VecDestroy(&ssls->dpsi));
  CHKERRQ(VecDestroy(&ssls->da));
  CHKERRQ(VecDestroy(&ssls->db));
  CHKERRQ(VecDestroy(&ssls->w));
  CHKERRQ(VecDestroy(&ssls->t1));
  CHKERRQ(VecDestroy(&ssls->t2));
  CHKERRQ(VecDestroy(&ssls->r1));
  CHKERRQ(VecDestroy(&ssls->r2));
  CHKERRQ(VecDestroy(&ssls->r3));
  CHKERRQ(VecDestroy(&ssls->dxfree));
  CHKERRQ(MatDestroy(&ssls->J_sub));
  CHKERRQ(MatDestroy(&ssls->Jpre_sub));
  CHKERRQ(ISDestroy(&ssls->fixed));
  CHKERRQ(ISDestroy(&ssls->free));
  CHKERRQ(PetscFree(tao->data));
  PetscFunctionReturn(0);
}

static PetscErrorCode TaoSolve_ASILS(Tao tao)
{
  TAO_SSLS                     *asls = (TAO_SSLS *)tao->data;
  PetscReal                    psi,ndpsi, normd, innerd, t=0;
  PetscInt                     nf;
  TaoLineSearchConvergedReason ls_reason;

  PetscFunctionBegin;
  /* Assume that Setup has been called!
     Set the structure for the Jacobian and create a linear solver. */

  CHKERRQ(TaoComputeVariableBounds(tao));
  CHKERRQ(TaoLineSearchSetObjectiveAndGradientRoutine(tao->linesearch,Tao_ASLS_FunctionGradient,tao));
  CHKERRQ(TaoLineSearchSetObjectiveRoutine(tao->linesearch,Tao_SSLS_Function,tao));

  /* Calculate the function value and fischer function value at the
     current iterate */
  CHKERRQ(TaoLineSearchComputeObjectiveAndGradient(tao->linesearch,tao->solution,&psi,asls->dpsi));
  CHKERRQ(VecNorm(asls->dpsi,NORM_2,&ndpsi));

  tao->reason = TAO_CONTINUE_ITERATING;
  while (1) {
    /* Check the termination criteria */
    CHKERRQ(PetscInfo(tao,"iter %D, merit: %g, ||dpsi||: %g\n",tao->niter, (double)asls->merit,  (double)ndpsi));
    CHKERRQ(TaoLogConvergenceHistory(tao,asls->merit,ndpsi,0.0,tao->ksp_its));
    CHKERRQ(TaoMonitor(tao,tao->niter,asls->merit,ndpsi,0.0,t));
    CHKERRQ((*tao->ops->convergencetest)(tao,tao->cnvP));
    if (TAO_CONTINUE_ITERATING != tao->reason) break;

    /* Call general purpose update function */
    if (tao->ops->update) {
      CHKERRQ((*tao->ops->update)(tao, tao->niter, tao->user_update));
    }
    tao->niter++;

    /* We are going to solve a linear system of equations.  We need to
       set the tolerances for the solve so that we maintain an asymptotic
       rate of convergence that is superlinear.
       Note: these tolerances are for the reduced system.  We really need
       to make sure that the full system satisfies the full-space conditions.

       This rule gives superlinear asymptotic convergence
       asls->atol = min(0.5, asls->merit*sqrt(asls->merit));
       asls->rtol = 0.0;

       This rule gives quadratic asymptotic convergence
       asls->atol = min(0.5, asls->merit*asls->merit);
       asls->rtol = 0.0;

       Calculate a free and fixed set of variables.  The fixed set of
       variables are those for the d_b is approximately equal to zero.
       The definition of approximately changes as we approach the solution
       to the problem.

       No one rule is guaranteed to work in all cases.  The following
       definition is based on the norm of the Jacobian matrix.  If the
       norm is large, the tolerance becomes smaller. */
    CHKERRQ(MatNorm(tao->jacobian,NORM_1,&asls->identifier));
    asls->identifier = PetscMin(asls->merit, 1e-2) / (1 + asls->identifier);

    CHKERRQ(VecSet(asls->t1,-asls->identifier));
    CHKERRQ(VecSet(asls->t2, asls->identifier));

    CHKERRQ(ISDestroy(&asls->fixed));
    CHKERRQ(ISDestroy(&asls->free));
    CHKERRQ(VecWhichBetweenOrEqual(asls->t1, asls->db, asls->t2, &asls->fixed));
    CHKERRQ(ISComplementVec(asls->fixed,asls->t1, &asls->free));

    CHKERRQ(ISGetSize(asls->fixed,&nf));
    CHKERRQ(PetscInfo(tao,"Number of fixed variables: %D\n", nf));

    /* We now have our partition.  Now calculate the direction in the
       fixed variable space. */
    CHKERRQ(TaoVecGetSubVec(asls->ff, asls->fixed, tao->subset_type, 0.0, &asls->r1));
    CHKERRQ(TaoVecGetSubVec(asls->da, asls->fixed, tao->subset_type, 1.0, &asls->r2));
    CHKERRQ(VecPointwiseDivide(asls->r1,asls->r1,asls->r2));
    CHKERRQ(VecSet(tao->stepdirection,0.0));
    CHKERRQ(VecISAXPY(tao->stepdirection, asls->fixed,1.0,asls->r1));

    /* Our direction in the Fixed Variable Set is fixed.  Calculate the
       information needed for the step in the Free Variable Set.  To
       do this, we need to know the diagonal perturbation and the
       right hand side. */

    CHKERRQ(TaoVecGetSubVec(asls->da, asls->free, tao->subset_type, 0.0, &asls->r1));
    CHKERRQ(TaoVecGetSubVec(asls->ff, asls->free, tao->subset_type, 0.0, &asls->r2));
    CHKERRQ(TaoVecGetSubVec(asls->db, asls->free, tao->subset_type, 1.0, &asls->r3));
    CHKERRQ(VecPointwiseDivide(asls->r1,asls->r1, asls->r3));
    CHKERRQ(VecPointwiseDivide(asls->r2,asls->r2, asls->r3));

    /* r1 is the diagonal perturbation
       r2 is the right hand side
       r3 is no longer needed

       Now need to modify r2 for our direction choice in the fixed
       variable set:  calculate t1 = J*d, take the reduced vector
       of t1 and modify r2. */

    CHKERRQ(MatMult(tao->jacobian, tao->stepdirection, asls->t1));
    CHKERRQ(TaoVecGetSubVec(asls->t1,asls->free,tao->subset_type,0.0,&asls->r3));
    CHKERRQ(VecAXPY(asls->r2, -1.0, asls->r3));

    /* Calculate the reduced problem matrix and the direction */
    if (!asls->w && (tao->subset_type == TAO_SUBSET_MASK || tao->subset_type == TAO_SUBSET_MATRIXFREE)) {
      CHKERRQ(VecDuplicate(tao->solution, &asls->w));
    }
    CHKERRQ(TaoMatGetSubMat(tao->jacobian, asls->free, asls->w, tao->subset_type,&asls->J_sub));
    if (tao->jacobian != tao->jacobian_pre) {
      CHKERRQ(TaoMatGetSubMat(tao->jacobian_pre, asls->free, asls->w, tao->subset_type, &asls->Jpre_sub));
    } else {
      CHKERRQ(MatDestroy(&asls->Jpre_sub));
      asls->Jpre_sub = asls->J_sub;
      CHKERRQ(PetscObjectReference((PetscObject)(asls->Jpre_sub)));
    }
    CHKERRQ(MatDiagonalSet(asls->J_sub, asls->r1,ADD_VALUES));
    CHKERRQ(TaoVecGetSubVec(tao->stepdirection, asls->free, tao->subset_type, 0.0, &asls->dxfree));
    CHKERRQ(VecSet(asls->dxfree, 0.0));

    /* Calculate the reduced direction.  (Really negative of Newton
       direction.  Therefore, rest of the code uses -d.) */
    CHKERRQ(KSPReset(tao->ksp));
    CHKERRQ(KSPSetOperators(tao->ksp, asls->J_sub, asls->Jpre_sub));
    CHKERRQ(KSPSolve(tao->ksp, asls->r2, asls->dxfree));
    CHKERRQ(KSPGetIterationNumber(tao->ksp,&tao->ksp_its));
    tao->ksp_tot_its+=tao->ksp_its;

    /* Add the direction in the free variables back into the real direction. */
    CHKERRQ(VecISAXPY(tao->stepdirection, asls->free, 1.0,asls->dxfree));

    /* Check the real direction for descent and if not, use the negative
       gradient direction. */
    CHKERRQ(VecNorm(tao->stepdirection, NORM_2, &normd));
    CHKERRQ(VecDot(tao->stepdirection, asls->dpsi, &innerd));

    if (innerd <= asls->delta*PetscPowReal(normd, asls->rho)) {
      CHKERRQ(PetscInfo(tao,"Gradient direction: %5.4e.\n", (double)innerd));
      CHKERRQ(PetscInfo(tao, "Iteration %D: newton direction not descent\n", tao->niter));
      CHKERRQ(VecCopy(asls->dpsi, tao->stepdirection));
      CHKERRQ(VecDot(asls->dpsi, tao->stepdirection, &innerd));
    }

    CHKERRQ(VecScale(tao->stepdirection, -1.0));
    innerd = -innerd;

    /* We now have a correct descent direction.  Apply a linesearch to
       find the new iterate. */
    CHKERRQ(TaoLineSearchSetInitialStepLength(tao->linesearch, 1.0));
    CHKERRQ(TaoLineSearchApply(tao->linesearch, tao->solution, &psi,asls->dpsi, tao->stepdirection, &t, &ls_reason));
    CHKERRQ(VecNorm(asls->dpsi, NORM_2, &ndpsi));
  }
  PetscFunctionReturn(0);
}

/* ---------------------------------------------------------- */
/*MC
   TAOASILS - Active-set infeasible linesearch algorithm for solving
       complementarity constraints

   Options Database Keys:
+ -tao_ssls_delta - descent test fraction
- -tao_ssls_rho - descent test power

  Level: beginner
M*/
PETSC_EXTERN PetscErrorCode TaoCreate_ASILS(Tao tao)
{
  TAO_SSLS       *asls;
  const char     *armijo_type = TAOLINESEARCHARMIJO;

  PetscFunctionBegin;
  CHKERRQ(PetscNewLog(tao,&asls));
  tao->data = (void*)asls;
  tao->ops->solve = TaoSolve_ASILS;
  tao->ops->setup = TaoSetUp_ASILS;
  tao->ops->view = TaoView_SSLS;
  tao->ops->setfromoptions = TaoSetFromOptions_SSLS;
  tao->ops->destroy = TaoDestroy_ASILS;
  tao->subset_type = TAO_SUBSET_SUBVEC;
  asls->delta = 1e-10;
  asls->rho = 2.1;
  asls->fixed = NULL;
  asls->free = NULL;
  asls->J_sub = NULL;
  asls->Jpre_sub = NULL;
  asls->w = NULL;
  asls->r1 = NULL;
  asls->r2 = NULL;
  asls->r3 = NULL;
  asls->t1 = NULL;
  asls->t2 = NULL;
  asls->dxfree = NULL;

  asls->identifier = 1e-5;

  CHKERRQ(TaoLineSearchCreate(((PetscObject)tao)->comm, &tao->linesearch));
  CHKERRQ(PetscObjectIncrementTabLevel((PetscObject)tao->linesearch, (PetscObject)tao, 1));
  CHKERRQ(TaoLineSearchSetType(tao->linesearch, armijo_type));
  CHKERRQ(TaoLineSearchSetOptionsPrefix(tao->linesearch,tao->hdr.prefix));
  CHKERRQ(TaoLineSearchSetFromOptions(tao->linesearch));

  CHKERRQ(KSPCreate(((PetscObject)tao)->comm, &tao->ksp));
  CHKERRQ(PetscObjectIncrementTabLevel((PetscObject)tao->ksp, (PetscObject)tao, 1));
  CHKERRQ(KSPSetOptionsPrefix(tao->ksp,tao->hdr.prefix));
  CHKERRQ(KSPSetFromOptions(tao->ksp));

  /* Override default settings (unless already changed) */
  if (!tao->max_it_changed) tao->max_it = 2000;
  if (!tao->max_funcs_changed) tao->max_funcs = 4000;
  if (!tao->gttol_changed) tao->gttol = 0;
  if (!tao->grtol_changed) tao->grtol = 0;
#if defined(PETSC_USE_REAL_SINGLE)
  if (!tao->gatol_changed) tao->gatol = 1.0e-6;
  if (!tao->fmin_changed)  tao->fmin = 1.0e-4;
#else
  if (!tao->gatol_changed) tao->gatol = 1.0e-16;
  if (!tao->fmin_changed) tao->fmin = 1.0e-8;
#endif
  PetscFunctionReturn(0);
}
