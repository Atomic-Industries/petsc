% \documentclass[letterpaper,12pt]{article}
\documentclass{article}
\usepackage[margin=1in]{geometry}

\usepackage{cite}
\usepackage{listings}
\usepackage{subcaption}
\usepackage{color}
\usepackage{amsmath,amssymb}

\usepackage{graphicx}
\usepackage{float}
\usepackage{gensymb}
\usepackage{physics}
\usepackage{listings}

\usepackage[final]{hyperref} % adds hyper links inside the generated pdf file
\hypersetup{
    colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=blue,          % color of internal links
    citecolor=blue,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=blue         
}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}


\let\vec\mathbf
\def\real{\mathbb{R}}

\pdfstringdefDisableCommands{%
  \def\lstinline#1{}%
}

\begin{document}

\section{Theory}

This discussion is based on \cite{brunton2016sindy} and \cite{shea2020sindy-bvp}.
I'm going to try to outline the general case. 
\begin{align}
\vec{u} &= \vec{u}(\vec{x}, t) \\
\frac{d\vec{u}}{dt} &= \frac{d\vec{u}}{dt}(\vec{u}, \vec{x}, t)
\end{align}
for $\vec{u} \in \real^{d_u}, \,\, \vec{x} \in \real^{d_x}, \,\, t \in \real$.
The goal of SINDy is to represent $\frac{d\vec{u}}{dt}$ in a basis $B$ of size
$p$ with sparse coefficients $\vec{c} \in \real^p$.
\begin{equation}
\frac{d\vec{u}}{dt} \approx \sum_{i=1}^p c_i \vec{b_i}
\end{equation}
\begin{align}
b_i \in B = \{\vec{1}, \vec{u}, \vec{x}, t, \vec{u}^2, \vec{u}\vec{x},\vec{u}t,\vec{x}^2,\vec{x}t,t^2,\hdots,\sin\vec{u},\cos{\vec{u}}, \frac{\partial\vec{u}}{\partial \vec{x}},\hdots\}
\end{align}
This will generally be represented as a linear system with discretized $\vec{U}$
and $\vec{X}$, with the columns of the matrix $\Theta$ represented basis
functions evaluated at specific $\vec{X}$ and $t$.
\begin{equation}
\frac{d\vec{U}}{dt} \approx \Theta(\vec{U}, \vec{X}, t) c
\end{equation}

Note that when $d_x \ne 1$ or $d_u \ne 1$, the vector terms in the basis shown above
aren't mathematically well-defined, but the idea is to include polynomial terms,
and these can also include polynomial terms of separate components of the
vector, and cross terms of those components. The functions shown in the basis
above are just examples; the main idea is that the basis can have any kind of
functions of $\vec{u}$, $\vec{x}$, and $t$.

\subsection{Simplest dimensional case, $d_x = 0$ and $d_u = 1$} \label{section:simplest}

To get to a multi-dimensional formulation, I'll start out by describing the case when $d_x = 0$ and $d_u = 1$.
\begin{align*}
u &= u(t) \\
\frac{du}{dt} &= \frac{du}{dt}(u, t)
\end{align*}
In this case, the collected data will be a one-dimensional set of values of $u$
at different times. Let $m$ be the number of data points, and $\vec{U} \in
\real^m$ be the set of data points, where $U_k$ is the $k$-th measurement of
$u$, with a corresponding derivative $\frac{d\vec{U}}{dt}$. Let $\vec{B_i} \in
\real^m$ be the $i$-th basis function evaluated at all $m$ data points, such
that $B_{k,i}$ is the basis function evaluated at the $k$-th measurement.
Then the equation to solve is the following:
\begin{equation*}
\frac{d\vec{U}}{dt} \approx \sum_{i=1}^p c_i \vec{B_i}
\end{equation*}
This can be written as a matrix multiplication, where $\vec{B_i}$ are the
columns of $\Theta \in \real^{m \times p}$.
\begin{equation}
\frac{d\vec{U}}{dt} \approx \Theta \vec{c}
\end{equation}
This can be solved for a sparse $\vec{c}$ with a sparse least squares solver. In
this case the basis functions are functions of the two variables $u$ and $t$.

\subsection{More outputs, $d_x = 0$ and $d_u \ge 1$} \label{section:more-outputs}

When $\vec{u}$ is a vector, each measurement will have $d_u$ values. In this
case the basis functions can be made of functions of the $d_u+1$ variables
$u_1,u_2,\hdots,u_{d_u}$ and $t$. To obtain separate sparse coefficients for
each output $\frac{du_i}{dt}$, the sparse regression can be performed on each
output dimension separately. Let $\vec{U_i} \in \real^{m}$ be the measurements
for output $i$ and $\vec{c_i} \in \real^p$ be the coefficients for output $i$.
Then we can solve the equation below to find all the coefficients.
\begin{equation}\label{eq:same-theta-eqs}
\frac{d\vec{U_i}}{dt} \approx \Theta \vec{c_i} \,\,\ \text{ for $i \in \{1,2,\hdots,d_u\} $}
\end{equation}

This can be structured as a single matrix equation by letting $\vec{U_i}$ be the
columns of the matrix $\vec{U} \in \real^{m \times d_u}$, and $\vec{c_i}$ be the
columns of the matrix $\vec{c} \in \real^{p \times d_u}$. Then the equation
becomes the following:
\begin{equation*}
\frac{d\vec{U}}{dt} \approx \Theta \vec{c}
\end{equation*}
This formulation makes each output $u_i$ depend on the same set of basis
functions, stored in $\Theta$. To write it as a single matrix equation but allow
each $u_i$ to have a different set of basis functions, a block diagonal
structure can be used.

Let $\Theta^{(i)} \in \real^{m \times p_i}$ be the data for the $p_i$ basis
functions to use for output $u_i$. Let $p = \sum p_i$ be the total number of
basis functions. Then the block diagonal matrix $\Theta' \in \real^{md_u \times p}$ can be constructed
using $\Theta^{(i)}$ along the diagonal. Then flatten the data $\vec{U}$ into a
vector $\vec{U'} \in \real^{md_u}$ and flatten the coefficients $\vec{c}$ into a
vector $\vec{c}' \in \real^{p}$.
\begin{equation}\label{eq:dx0-dudt-separate-theta}
\frac{d\vec{U'}}{dt} = 
\begin{bmatrix}
\frac{d\vec{U_1}}{dt} \\ \frac{d\vec{U_2}}{dt} \\ \vdots \\ \frac{d\vec{U_{d_u}}}{dt}
\end{bmatrix}
\approx
\begin{bmatrix}
\Theta^{(1)} \\
& \Theta^{(2)} \\
& & \ddots \\
& & & \Theta^{(d_u)} \\
\end{bmatrix}
\begin{bmatrix}
\vec{c_1} \\ \vec{c_2} \\ \vdots \\ \vec{c_{d_u}}
\end{bmatrix}
= \Theta' \vec{c}'
\end{equation}
A possible problem with this formulation is that a sparse solver may enforce
sparsity on $\vec{c}$, but the desired sparsity is actually on each separate
$\vec{c_i}$. The problem is that a larger value in $\vec{c_i}$ may make the
values in $\vec{c_j}$ smaller for some $i$ and $j$. For this reason, it may be
more beneficial to use a sparse solver on the following separate equations instead:
\begin{equation}\label{eq:diff-theta-eqs}
\frac{d\vec{U_i}}{dt} \approx \Theta^{(i)} \vec{c_i} \,\,\ \text{ for $i \in \{1,2,\hdots,d_u\} $}
\end{equation}

\subsection{Handling coordinates, $d_x = 1$ and $d_u = 1$}
In this case, we have a scalar function with 1D coordinates $u = u(x,t)$. In
this case, our measurements will be snapshots of $u(x)$ at different times. Let
$n$ be the number of slices of the $x$ dimension, and $m$ be the number of
slices in the $t$ dimension. Let $\vec{U} \in \real^{m \times n}$ be the set of
data points where each column $\vec{U_j} \in \real^m = u(x_j, t)$ is the value
of $u$ at $x_j$ fixed time for each different time $t$.

This can be thought of as monitoring $n$ separate outputs similary to the case
in Section~\ref{section:more-outputs}, but additional structure can be obtained by
assuming that $u$ is governed by a PDE. In that case, $\frac{du}{dt}(u,x_j,t)$
will only depend on $x_j$, $u$, and the spatial derivatives of $u$ at $x_j$.
Thus, the linear system should be set up so that there is no dependence between
separate $x$ coordinates; each $x_j$ will have a separate basis matrix
$\Theta^{(j)}(x_j, u(x_j,t)) \in \real^{m \times p}$.

\paragraph{Varying coefficients}
This can be done in a similar manner as
Equation~\ref{eq:dx0-dudt-separate-theta}. Note that each point should use the
same set of basis functions. Let the number of basis functions at each point be
$p$. The block diagonal matrix $\Theta' \in \real^{mn \times np}$ has
$\Theta^{(j)}$ along the diagonal. Each point $x_j$ has a coefficient vector
$\vec{c_j} \in \real^p$
\begin{equation}
\frac{d\vec{U'}}{dt} = 
\begin{bmatrix}
\frac{d\vec{U_1}}{dt} \\ \frac{d\vec{U_2}}{dt} \\ \vdots \\ \frac{d\vec{U_n}}{dt}
\end{bmatrix}
\approx
\begin{bmatrix}
\Theta^{(1)} \\
& \Theta^{(2)} \\
& & \ddots \\
& & & \Theta^{(n)} \\
\end{bmatrix}
\begin{bmatrix}
\vec{c_1} \\ \vec{c_2} \\ \vdots \\ \vec{c_{n}}
\end{bmatrix}
= \Theta' \vec{c}'
\end{equation}
This formulation allows the coefficient vector to vary across space, since each
point has a separate set of basis coefficients. This formulation is used on
\cite{shea2020sindy-bvp}. An algorithm like Sequential Grouped Threshold Ridge
Regression in \cite{shea2020sindy-bvp} can be used to ensure that each $x$
coordinate uses the same sparsity for the basis functions.

\paragraph{Constant coefficients}
Alternatively, it may be desirable for the coefficients to not vary across
space; instead, a single coefficient vector should represent all points. In this
case, the input data and the matrices can be stacked so that each $x$ position
is effectively an independent data point. The matrix $\Theta' \in \real^{mn
\times p}$ can be constructed by stacking $\Theta^{(i)}$ rowwise. The
data $\vec{U}$ can be stacked into vector $\vec{U'} \in \real^{md_u}$. Each
point $x_j$ has the same coefficient vector $\vec{c} \in \real^p$

\begin{equation}
\frac{d\vec{U'}}{dt} = 
\begin{bmatrix}
\frac{d\vec{U_1}}{dt} \\ \frac{d\vec{U_2}}{dt} \\ \vdots \\ \frac{d\vec{U_{n}}}{dt}
\end{bmatrix}
\approx
\begin{bmatrix}
\Theta^{(1)} \\
\Theta^{(2)} \\
\vdots \\
\Theta^{(n)} \\
\end{bmatrix}
\vec{c}
= \Theta' \vec{c}
\end{equation}

\subsection{Full multi-dimensional case, $d_x \ge 1$ and $d_u \ge 1$}
This simply combines the descriptions of the previous two sections. The $d_x$
coordinates can be linearized in some manner so that they can be referenced with
a single index $j$.

Each dimension $i \in \{1,2,\hdots,d_u \}$ can be treated
separately, either as a separate column as used in
Equation~\ref{eq:same-theta-eqs} and~\ref{eq:diff-theta-eqs} or as a stack next
to a block diagonal matrix as used in Equation~\ref{eq:dx0-dudt-separate-theta}.


\section{Examples}

\subsection{sindy\_sine}
In this example, $d_x = 0$ (no coordinates) and $d_u = 1$. There is no time dependence.
\begin{equation*}
\frac{dU}{dt} = -\sin(U)
\end{equation*}


\subsection{sindy\_sine\_cosine}
In this example, $d_x = 0$ (no coordinates) and $d_u = 2$. There is no time dependence.
\begin{equation*}
\frac{d\vec{U}}{dt} =
\begin{bmatrix}
-\sin(U_1) \\ \cos(U_2)
\end{bmatrix}
\end{equation*}


\subsection{lorenz}
In this example, $d_x = 0$ (no coordinates) and $d_u = 3$. There is no time dependence.
\begin{equation*}
\frac{d\vec{U}}{dt} =
\begin{bmatrix}
-\sin(U_1) \\ \cos(U_2)
\end{bmatrix}
\end{equation*}


\subsection{lorenz96}
In this example, $d_x = 0$ (no coordinates) and $d_u = 36$. There is no time dependence.
\begin{equation*}
\frac{dU_i}{dt} = (U_{i+1} - U_{i-2}) U_{i-1} - U_i + F
\end{equation*}

\subsection{pde\_power\_grid}
In this example, $d_x = 2$ and $d_u = 1$, and there is time dependence.
\begin{align*}
\frac{dU}{dt} &= - \frac{\partial x_1}{\partial t} \frac{\partial U}{\partial x_1}
                 - \frac{\partial x_2}{\partial t} \frac{\partial U}{\partial x_2}
                 + f(t) \frac{\partial^2 U}{\partial x_2^2}
\\ \frac{\partial x_1}{\partial t} &= (x_2 - \omega_s)
\\ \frac{\partial x_2}{\partial t} &= \frac{\omega_s}{2H}(P_m - P_{max}\sin(x_1))
\\ f(t) &= \left(\frac{\lambda \omega_s}{2H}\right) ^ 2 q (1-e^{-t/\lambda})
\end{align*}



\bibliographystyle{unsrt}
\bibliography{sources}




\end{document}